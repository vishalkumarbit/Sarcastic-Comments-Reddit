{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\80316\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function-1: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(data):\n",
    "    if 'label' in data.columns:\n",
    "        data.drop('label', axis=1, inplace=True)\n",
    "    data.drop(['date', 'created_utc'], axis=1, inplace=True)\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    def decontracted(phrase):\n",
    "        # specific\n",
    "        phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "        # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "\n",
    "        # Remove Emoji\n",
    "    def deEmojify(text):\n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "        return regrex_pattern.sub(r'',text)\n",
    "\n",
    "    def preprocess_text(text_data):\n",
    "        preprocessed_text = []\n",
    "        # tqdm is for printing the status bar\n",
    "        for sentance in tqdm(text_data):\n",
    "            sent = decontracted(sentance)\n",
    "            sent=deEmojify(sent)\n",
    "            sent = sent.replace('\\\\r', ' ')\n",
    "            sent = sent.replace('\\\\n', ' ')\n",
    "            sent = sent.replace('\\\\\"', ' ')\n",
    "            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "            # https://gist.github.com/sebleier/554280\n",
    "            sent = ' '.join(e for e in sent.split() if e not in stop_words)\n",
    "            preprocessed_text.append(sent.lower().strip())\n",
    "        return preprocessed_text\n",
    "    \n",
    "    data['comment'] = preprocess_text(data['comment'].values)\n",
    "    data['parent_comment'] = preprocess_text(data['parent_comment'].values)\n",
    "        \n",
    "    data['subreddit'] = data['subreddit'].str.replace(' ','')\n",
    "    data['subreddit'] = data['subreddit'].str.replace('-','_')\n",
    "    data['subreddit'] = data['subreddit'].str.lower()\n",
    "    \n",
    "    data['author'] = data['author'].str.replace(' ','')\n",
    "    data['author'] = data['author'].str.replace('-','_')\n",
    "    data['author'] = data['author'].str.lower()\n",
    "    \n",
    "    neg_comment = []\n",
    "    neu_comment = []\n",
    "    pos_comment = []\n",
    "    comp_comment = []\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for sentence in tqdm(data['comment']):\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        neg_comment.append(ss['neg'])\n",
    "        neu_comment.append(ss['neu'])\n",
    "        pos_comment.append(ss['pos'])\n",
    "        comp_comment.append(ss['compound'])\n",
    "\n",
    "    data['Neg_comment'] = neg_comment\n",
    "    data['Neu_comment'] = neu_comment\n",
    "    data['Pos_comment'] = pos_comment\n",
    "    data['Compound_comment'] = comp_comment\n",
    "    \n",
    "    neg_pcomment = []\n",
    "    neu_pcomment = []\n",
    "    pos_pcomment = []\n",
    "    comp_pcomment = []\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for sentence in tqdm(data['parent_comment']):\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        neg_pcomment.append(ss['neg'])\n",
    "        neu_pcomment.append(ss['neu'])\n",
    "        pos_pcomment.append(ss['pos'])\n",
    "        comp_pcomment.append(ss['compound'])\n",
    "    \n",
    "    data['Neg_pcomment'] = neg_pcomment\n",
    "    data['Neu_pcomment'] = neu_pcomment\n",
    "    data['Pos_pcomment'] = pos_pcomment\n",
    "    data['Compound_pcomment'] = comp_pcomment\n",
    "    \n",
    "    data['comment_len']=data['comment'].apply(lambda x:len(x.split()))\n",
    "    data['pcomment_len']=data['parent_comment'].apply(lambda x:len(x.split()))\n",
    "    \n",
    "    cat_author, cat_subreddit = pickle.load(open(\"cat.pkl\", 'rb'))\n",
    "    data['author'] = cat_author.transform(data['author'])\n",
    "    data['subreddit'] = cat_subreddit.transform(data['subreddit'])\n",
    "    \n",
    "    scaler_score, scaler_ups, scaler_negc, scaler_neuc, scaler_posc, scaler_compc, scaler_negpc, scaler_neupc, scaler_pospc, scaler_comppc, scaler_comlen, scaler_pcomlen = pickle.load(open(\"scale.pkl\", 'rb'))\n",
    "    data['score'] = scaler_score.transform(data['score'].values.reshape(-1,1))    \n",
    "    data['ups'] = scaler_ups.transform(data['ups'].values.reshape(-1,1))\n",
    "    data['Neg_comment'] = scaler_negc.transform(data['Neg_comment'].values.reshape(-1,1))\n",
    "    data['Neu_comment'] = scaler_neuc.transform(data['Neu_comment'].values.reshape(-1,1))\n",
    "    data['Pos_comment'] = scaler_posc.transform(data['Pos_comment'].values.reshape(-1,1))\n",
    "    data['Compound_comment'] = scaler_compc.transform(data['Compound_comment'].values.reshape(-1,1))\n",
    "    data['Neg_pcomment'] = scaler_negpc.transform(data['Neg_pcomment'].values.reshape(-1,1))\n",
    "    data['Neu_pcomment'] = scaler_neupc.transform(data['Neu_pcomment'].values.reshape(-1,1))\n",
    "    data['Pos_pcomment'] = scaler_pospc.transform(data['Pos_pcomment'].values.reshape(-1,1))\n",
    "    data['Compound_pcomment'] = scaler_comppc.transform(data['Compound_pcomment'].values.reshape(-1,1))\n",
    "    data['comment_len'] = scaler_comlen.transform(data['comment_len'].values.reshape(-1,1))\n",
    "    data['pcomment_len'] = scaler_pcomlen.transform(data['pcomment_len'].values.reshape(-1,1))\n",
    "    \n",
    "    text_features = data[['comment', 'parent_comment']]\n",
    "    data.drop(['comment', 'parent_comment'], axis=1, inplace=True)\n",
    "    \n",
    "    token_comment, token_pcomment =  pickle.load(open('tokens.pkl','rb'))\n",
    "    sequence_com = token_comment.texts_to_sequences(text_features['comment'])\n",
    "    pad_comment = pad_sequences(sequence_com, maxlen=50, padding='post')\n",
    "    sequence_pcom = token_pcomment.texts_to_sequences(text_features['parent_comment'])\n",
    "    pad_pcomment = pad_sequences(sequence_pcom, maxlen=500, padding='post')\n",
    "    \n",
    "    num_data = data.values\n",
    "    \n",
    "    model = keras.models.load_model('final_model.h5')\n",
    "        \n",
    "    predictions = model.predict([pad_comment, pad_pcomment, num_data])\n",
    "    \n",
    "    prediction_list = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        if prediction >= 0.5:\n",
    "            prediction_list.append(1)\n",
    "            prediction = 'Sarcastic'\n",
    "            return prediction\n",
    "        else:\n",
    "            prediction_list.append(0)\n",
    "            prediction = 'Non-Sarcastic'\n",
    "            return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204933</th>\n",
       "      <td>1</td>\n",
       "      <td>Yellow snow flavored :D</td>\n",
       "      <td>Vapeisntsobad</td>\n",
       "      <td>electronic_cigarette</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05</td>\n",
       "      <td>2016-05-23 00:53:12</td>\n",
       "      <td>What flavor juice do you wish existed but you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                  comment         author             subreddit  \\\n",
       "204933      1  Yellow snow flavored :D  Vapeisntsobad  electronic_cigarette   \n",
       "\n",
       "        score  ups  downs     date          created_utc  \\\n",
       "204933      0    0      0  2016-05  2016-05-23 00:53:12   \n",
       "\n",
       "                                           parent_comment  \n",
       "204933  What flavor juice do you wish existed but you ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train-balanced-sarcasm.csv')\n",
    "sample_data = df.sample(1)\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1006.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 661.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 144.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Non-Sarcastic'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fun_1(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(data, y_true):\n",
    "    if 'label' in data.columns:\n",
    "        data.drop('label', axis=1, inplace=True)\n",
    "    data.drop(['date', 'created_utc'], axis=1, inplace=True)\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    def decontracted(phrase):\n",
    "        # specific\n",
    "        phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "        # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "\n",
    "        # Remove Emoji\n",
    "    def deEmojify(text):\n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "        return regrex_pattern.sub(r'',text)\n",
    "\n",
    "    def preprocess_text(text_data):\n",
    "        preprocessed_text = []\n",
    "        # tqdm is for printing the status bar\n",
    "        for sentance in tqdm(text_data):\n",
    "            sent = decontracted(sentance)\n",
    "            sent=deEmojify(sent)\n",
    "            sent = sent.replace('\\\\r', ' ')\n",
    "            sent = sent.replace('\\\\n', ' ')\n",
    "            sent = sent.replace('\\\\\"', ' ')\n",
    "            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "            # https://gist.github.com/sebleier/554280\n",
    "            sent = ' '.join(e for e in sent.split() if e not in stop_words)\n",
    "            preprocessed_text.append(sent.lower().strip())\n",
    "        return preprocessed_text\n",
    "    \n",
    "    data['comment'] = preprocess_text(data['comment'].values)\n",
    "    data['parent_comment'] = preprocess_text(data['parent_comment'].values)\n",
    "        \n",
    "    data['subreddit'] = data['subreddit'].str.replace(' ','')\n",
    "    data['subreddit'] = data['subreddit'].str.replace('-','_')\n",
    "    data['subreddit'] = data['subreddit'].str.lower()\n",
    "    \n",
    "    data['author'] = data['author'].str.replace(' ','')\n",
    "    data['author'] = data['author'].str.replace('-','_')\n",
    "    data['author'] = data['author'].str.lower()\n",
    "    \n",
    "    neg_comment = []\n",
    "    neu_comment = []\n",
    "    pos_comment = []\n",
    "    comp_comment = []\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for sentence in tqdm(data['comment']):\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        neg_comment.append(ss['neg'])\n",
    "        neu_comment.append(ss['neu'])\n",
    "        pos_comment.append(ss['pos'])\n",
    "        comp_comment.append(ss['compound'])\n",
    "\n",
    "    data['Neg_comment'] = neg_comment\n",
    "    data['Neu_comment'] = neu_comment\n",
    "    data['Pos_comment'] = pos_comment\n",
    "    data['Compound_comment'] = comp_comment\n",
    "    \n",
    "    neg_pcomment = []\n",
    "    neu_pcomment = []\n",
    "    pos_pcomment = []\n",
    "    comp_pcomment = []\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for sentence in tqdm(data['parent_comment']):\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        neg_pcomment.append(ss['neg'])\n",
    "        neu_pcomment.append(ss['neu'])\n",
    "        pos_pcomment.append(ss['pos'])\n",
    "        comp_pcomment.append(ss['compound'])\n",
    "    \n",
    "    data['Neg_pcomment'] = neg_pcomment\n",
    "    data['Neu_pcomment'] = neu_pcomment\n",
    "    data['Pos_pcomment'] = pos_pcomment\n",
    "    data['Compound_pcomment'] = comp_pcomment\n",
    "    \n",
    "    data['comment_len']=data['comment'].apply(lambda x:len(x.split()))\n",
    "    data['pcomment_len']=data['parent_comment'].apply(lambda x:len(x.split()))\n",
    "    \n",
    "    cat_author, cat_subreddit = pickle.load(open(\"cat.pkl\", 'rb'))\n",
    "    data['author'] = cat_author.transform(data['author'])\n",
    "    data['subreddit'] = cat_subreddit.transform(data['subreddit'])\n",
    "    \n",
    "    scaler_score, scaler_ups, scaler_negc, scaler_neuc, scaler_posc, scaler_compc, scaler_negpc, scaler_neupc, scaler_pospc, scaler_comppc, scaler_comlen, scaler_pcomlen = pickle.load(open(\"scale.pkl\", 'rb'))\n",
    "    data['score'] = scaler_score.transform(data['score'].values.reshape(-1,1))    \n",
    "    data['ups'] = scaler_ups.transform(data['ups'].values.reshape(-1,1))\n",
    "    data['Neg_comment'] = scaler_negc.transform(data['Neg_comment'].values.reshape(-1,1))\n",
    "    data['Neu_comment'] = scaler_neuc.transform(data['Neu_comment'].values.reshape(-1,1))\n",
    "    data['Pos_comment'] = scaler_posc.transform(data['Pos_comment'].values.reshape(-1,1))\n",
    "    data['Compound_comment'] = scaler_compc.transform(data['Compound_comment'].values.reshape(-1,1))\n",
    "    data['Neg_pcomment'] = scaler_negpc.transform(data['Neg_pcomment'].values.reshape(-1,1))\n",
    "    data['Neu_pcomment'] = scaler_neupc.transform(data['Neu_pcomment'].values.reshape(-1,1))\n",
    "    data['Pos_pcomment'] = scaler_pospc.transform(data['Pos_pcomment'].values.reshape(-1,1))\n",
    "    data['Compound_pcomment'] = scaler_comppc.transform(data['Compound_pcomment'].values.reshape(-1,1))\n",
    "    data['comment_len'] = scaler_comlen.transform(data['comment_len'].values.reshape(-1,1))\n",
    "    data['pcomment_len'] = scaler_pcomlen.transform(data['pcomment_len'].values.reshape(-1,1))\n",
    "    \n",
    "    text_features = data[['comment', 'parent_comment']]\n",
    "    data.drop(['comment', 'parent_comment'], axis=1, inplace=True)\n",
    "    \n",
    "    token_comment, token_pcomment =  pickle.load(open('tokens.pkl','rb'))\n",
    "    sequence_com = token_comment.texts_to_sequences(text_features['comment'])\n",
    "    pad_comment = pad_sequences(sequence_com, maxlen=50, padding='post')\n",
    "    sequence_pcom = token_pcomment.texts_to_sequences(text_features['parent_comment'])\n",
    "    pad_pcomment = pad_sequences(sequence_pcom, maxlen=500, padding='post')\n",
    "    \n",
    "    num_data = data.values\n",
    "    \n",
    "    model = keras.models.load_model('final_model.h5')\n",
    "        \n",
    "    predictions = model.predict([pad_comment, pad_pcomment, num_data])\n",
    "    \n",
    "    prediction_list = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        if prediction >= 0.5:\n",
    "            prediction_list.append(1)\n",
    "            \n",
    "        else:\n",
    "            prediction_list.append(0)\n",
    "            \n",
    "    y_pred = np.array(prediction_list)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>776248</th>\n",
       "      <td>0</td>\n",
       "      <td>There is a difference when you bring something...</td>\n",
       "      <td>ZaynRocks</td>\n",
       "      <td>SquaredCircle</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-03</td>\n",
       "      <td>2015-03-07 19:15:29</td>\n",
       "      <td>There's a difference when you criticize the pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                            comment     author  \\\n",
       "776248      0  There is a difference when you bring something...  ZaynRocks   \n",
       "\n",
       "            subreddit  score  ups  downs     date          created_utc  \\\n",
       "776248  SquaredCircle      3    3      0  2015-03  2015-03-07 19:15:29   \n",
       "\n",
       "                                           parent_comment  \n",
       "776248  There's a difference when you criticize the pr...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train-balanced-sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>913917</th>\n",
       "      <td>1</td>\n",
       "      <td>But but.. How are those stupid Christians gonn...</td>\n",
       "      <td>MNREDR</td>\n",
       "      <td>cringepics</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>2013-04-16 18:48:14</td>\n",
       "      <td>I would like to ask my fellow atheists to lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931108</th>\n",
       "      <td>1</td>\n",
       "      <td>Further evidence that there are likely too man...</td>\n",
       "      <td>zxcvb94105</td>\n",
       "      <td>Green</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-06</td>\n",
       "      <td>2013-06-16 06:25:45</td>\n",
       "      <td>Plant erupts in flames while chemical industry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208340</th>\n",
       "      <td>1</td>\n",
       "      <td>Well technically reddit is a private interface...</td>\n",
       "      <td>TheBuffaloSabres</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2016-07-03 00:51:20</td>\n",
       "      <td>Yeah, I've been told that too, I've been banne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624824</th>\n",
       "      <td>0</td>\n",
       "      <td>How does it work exactly?</td>\n",
       "      <td>AbusedToasters</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-08</td>\n",
       "      <td>2015-08-19 22:07:54</td>\n",
       "      <td>Infinity Monkey Bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956517</th>\n",
       "      <td>0</td>\n",
       "      <td>Road bike sub $400, I would look on craigslist...</td>\n",
       "      <td>aggieotis</td>\n",
       "      <td>bicycling</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-05</td>\n",
       "      <td>2012-05-30 19:43:09</td>\n",
       "      <td>What bikes would you recommend?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                            comment  \\\n",
       "913917      1  But but.. How are those stupid Christians gonn...   \n",
       "931108      1  Further evidence that there are likely too man...   \n",
       "208340      1  Well technically reddit is a private interface...   \n",
       "624824      0                          How does it work exactly?   \n",
       "956517      0  Road bike sub $400, I would look on craigslist...   \n",
       "\n",
       "                  author          subreddit  score  ups  downs     date  \\\n",
       "913917            MNREDR         cringepics      1    1      0  2013-04   \n",
       "931108        zxcvb94105              Green      1    1      0  2013-06   \n",
       "208340  TheBuffaloSabres         The_Donald      1    1      0  2016-07   \n",
       "624824    AbusedToasters  mildlyinteresting      1    1      0  2015-08   \n",
       "956517         aggieotis          bicycling      1    1      0  2012-05   \n",
       "\n",
       "                created_utc                                     parent_comment  \n",
       "913917  2013-04-16 18:48:14  I would like to ask my fellow atheists to lear...  \n",
       "931108  2013-06-16 06:25:45  Plant erupts in flames while chemical industry...  \n",
       "208340  2016-07-03 00:51:20  Yeah, I've been told that too, I've been banne...  \n",
       "624824  2015-08-19 22:07:54                                Infinity Monkey Bar  \n",
       "956517  2012-05-30 19:43:09                    What bikes would you recommend?  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = df.sample(50)\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 10364.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 4494.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 3882.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1372.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fun_1(sample_data, sample_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-balanced-sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>781858</th>\n",
       "      <td>1</td>\n",
       "      <td>you should file a dmca complaint</td>\n",
       "      <td>BrokenStool</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>2014-12-16 05:43:57</td>\n",
       "      <td>This skin looks exactly like the SA Highwayman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                           comment       author        subreddit  \\\n",
       "781858      1  you should file a dmca complaint  BrokenStool  GlobalOffensive   \n",
       "\n",
       "        score  ups  downs     date          created_utc  \\\n",
       "781858      1    1      0  2014-12  2014-12-16 05:43:57   \n",
       "\n",
       "                                           parent_comment  \n",
       "781858  This skin looks exactly like the SA Highwayman...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = df.sample(1)\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This skin looks exactly like the SA Highwayman...Did they steal the art? Or did they just change the name with permission?'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['parent_comment'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you should file a dmca complaint'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['comment'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BrokenStool'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['author'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GlobalOffensive'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['subreddit'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
